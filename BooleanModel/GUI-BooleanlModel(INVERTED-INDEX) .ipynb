{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all Documents\n",
    "D={}\n",
    "for x in range(50):\n",
    "    x=x+1\n",
    "    file=\"Documents/\"+str(x)+\".txt\"\n",
    "    D[x]=open(file).read()\n",
    "        \n",
    "#appended all documents to allDoc\n",
    "allDoc=\"\"\n",
    "for x in range(50):\n",
    "    x=x+1\n",
    "    allDoc=allDoc+\" \\n\"+D[x]\n",
    "        \n",
    "#Tokens\n",
    "tokens=nltk.word_tokenize(allDoc)\n",
    "    \n",
    "#Unique Tokens \n",
    "tokens=list(set(tokens))\n",
    "    \n",
    "#Remove Special characters\n",
    "removetable=str.maketrans(\"\", \"\", \"'!@#$%^&*()_=-\\|][:';:,<.>/?`~\")\n",
    "tokens=[x.translate(removetable) for x in tokens]\n",
    "    \n",
    "#Importing Stoplist\n",
    "stopWord=open(\"Stopword-List.txt\").read()\n",
    "stopWord=nltk.word_tokenize(stopWord)\n",
    "    \n",
    "#Removing Stop Words\n",
    "tokens=set(tokens)-set(stopWord)\n",
    "tokens=list(tokens)\n",
    "    \n",
    "#Decapitalized\n",
    "tokens=[element.lower() for element in tokens]\n",
    "    \n",
    "#Sorted Tokens\n",
    "tokens=sorted(tokens)\n",
    "    \n",
    "#Document wise Tokenization\n",
    "docToken={}\n",
    "for x in range(50):\n",
    "    x=x+1\n",
    "    docToken[x]=nltk.word_tokenize(D[x])\n",
    "        \n",
    "#unique Token Doc wise\n",
    "for x in range(50):\n",
    "    x=x+1\n",
    "    docToken[x]=set(docToken[x])\n",
    "    docToken[x]=list(docToken[x])\n",
    "        \n",
    "#Remove Special characters Doc Wise\n",
    "removetable=str.maketrans(\"\", \"\", \"'!@#$%^&*()_=-\\|][:';:,<.>/?`~\")\n",
    "for x in range(50):\n",
    "    x=x+1\n",
    "    docToken[x]=[y.translate(removetable) for y in docToken[x]]\n",
    "        \n",
    "        \n",
    "#doc wise sorted\n",
    "for x in range(50):\n",
    "        x=x+1\n",
    "        docToken[x]=sorted(docToken[x])\n",
    "        \n",
    "#Decaptilized Doc Wise\n",
    "for x in range(50):\n",
    "    x=x+1\n",
    "    docToken[x]=[element.lower() for element in docToken[x]]\n",
    "        \n",
    "postinglist={}\n",
    "lst=[]\n",
    "    \n",
    "count=0\n",
    "for x in range(len(tokens)):\n",
    "    lst=[]\n",
    "    for y in range(50):\n",
    "        y=y+1\n",
    "        \n",
    "        if tokens[x] in docToken[y]:\n",
    "            lst.append(y)\n",
    "            \n",
    "    postinglist[x]=lst\n",
    "        \n",
    "dict={}\n",
    "for x in range(len(tokens)):\n",
    "    dict.update({tokens[x]:postinglist[x]})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_entry_fields():\n",
    "    query=e1.get()\n",
    "    qt=nltk.word_tokenize(query)\n",
    "    print(qt)\n",
    "    #Remove Special characters\n",
    "    removetable=str.maketrans(\"\", \"\", \"'!@#$%^&*()_=-\\|][:';:,<.>/?`~\")\n",
    "    qt=[x.translate(removetable) for x in qt]\n",
    "    \n",
    "    #Decapitalized\n",
    "    qt=[element.lower() for element in qt]\n",
    "    \n",
    "    ans=[]\n",
    "    temp=[]\n",
    "    if len(qt) == 1:\n",
    "        try:\n",
    "            ans=dict[qt[0]]\n",
    "        except KeyError:\n",
    "            print(\"Key Error\")\n",
    "        if not ans:\n",
    "            printString = \"Result for the Query : \" + qt[0]\n",
    "            print (\"0 documents returned as there is no match\")\n",
    "\n",
    "        else:\n",
    "            print (\"Result for the Query : \" + qt[0])\n",
    "            print (\"Total documents retrieved : \" + str(len(ans)))\n",
    "            print(\"Documents: \")\n",
    "            print(ans)\n",
    "            \n",
    "        e2.delete(0,END)\n",
    "        e2.insert(15,ans)\n",
    "                \n",
    "                \n",
    "    else:\n",
    "        x=0\n",
    "        for i in range(len(qt)):\n",
    "        \n",
    "            if (x>(len(qt))+i-3):\n",
    "                break   \n",
    "            if (qt[i+1]==\"and\"):\n",
    "                try:\n",
    "                    temp=set(dict[qt[i]]).intersection(set(dict[qt[i+2]]))\n",
    "                    ans.append(temp)\n",
    "                except KeyError:\n",
    "                    print(\"Key Error\")\n",
    "                    ans.append([])\n",
    "            #------------------------------#\n",
    "                \n",
    "            elif (qt[i+1]==\"or\"):\n",
    "                try:\n",
    "                    temp=set(dict[qt[i]]).union(set(dict[qt[i+2]]))\n",
    "                    ans.append(temp)\n",
    "                except KeyError:\n",
    "                    print(\"Key Error\")\n",
    "                    ans.append([])\n",
    "            \n",
    "                #---------------------------------#\n",
    "            elif (qt[i+1]==\"not\"):\n",
    "                try:\n",
    "                    ans.append(set(dict[qt[i]]).difference(set(dict[qt[i+2]])))\n",
    "                except KeyError:\n",
    "                    print(\"Key Error\")\n",
    "                    ans.append([])\n",
    "            x=x+2\n",
    "            \n",
    "        \n",
    "        print (\"Result for the Query : \")\n",
    "        print(query)\n",
    "        print (\"Total documents retrieved : \" + str(len(ans[-1])))\n",
    "        print(\"Documents: \")\n",
    "        print(ans[-1])\n",
    "        e2.delete(0,END)\n",
    "        e2.insert(15,ans[-1])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'and', 'dog']\n",
      "Result for the Query : \n",
      "cat and dog\n",
      "Total documents retrieved : 3\n",
      "Documents: \n",
      "{25, 20, 13}\n"
     ]
    }
   ],
   "source": [
    "master = Tk()\n",
    "master.geometry('900x200')\n",
    "master.title(\"Boolean Reterival Model Using Inverted Index\")\n",
    "\n",
    "Label(master, text=\"Enter Query (and, or and not) : \",width=20,font=(\"bold\", 10),padx=10, pady=20).grid(row=0)\n",
    "Label(master, text=\"Result (Document IDs:)\",width=20,font=(\"bold\", 10),padx=10, pady=20).grid(row=1)\n",
    "\n",
    "\n",
    "e1 = Entry(master,width=100)\n",
    "e2 = Entry(master,width=100)\n",
    "e1.insert(15,\"cat and dog\")\n",
    "\n",
    "e1.grid(row=0, column=1)\n",
    "e2.grid(row=1, column=1)\n",
    "\n",
    "Button(master, text='Search', command=show_entry_fields).grid(row=3, column=1, sticky=W, pady=4)\n",
    "\n",
    "mainloop( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
